---
layout: post
title: Understanding Hidden States In RNN Part-1!
---

**Note:** Here we will be making a way to understand Recurrent Neural Network using Neural Network ideas, so it is required to have some basic working idea of Neural Network. 

<br><br>
The blog is divided into 4 sections . It will guide you step by step understanding the transition from NN to RNN.


1. [Drawbacks of Neural Networks by using an example to point out difference](#point_1)
2. [Making way from Neural Network to Recurrent Neural Network(NN)](#point_2) 
3. [Birth of RNN](#point_3)
4. [BPTT for RNN](#point_4)


Starting with first section , we are gonna look at why Neural Networks fails at understanding sequential data.


<a name="point_1"></a>

___


### 1. Drawbacks of Neural Networks
___


The Neural Network as we know is of neurons of previous layer providing inputs to the succeeding layer of neurons . Neural Networks are mere function approximators, where we can either get a probabilistic value (using sigmoid or softmax) or clip a value off (relu functions). After years of research ,Neural Networks are the closest idea on how our brain functions.

Let’s see a small example . We will feed two sentences to a neural network 

![rnn example]({{ site.baseurl }}/images/rnn_1/RNN_example.png)



Now ,we know that A is a question and B is a declaration . We hope that the network can identify that these as two different statements. In order to feed the data to a Neural Network we will use one hot vector to represent the data: 


you: [0 1 0] 

are: [1 0 0]

good: [0 0 1] 

![nn feed]({{ site.baseurl }}/images/rnn_1/NN_1.png)


These two sentences A(“you are good”) and B(“are you good”) at least makes sense to us. Now think of a **sentence C (“good you are”)**. Does it make sense?


![not at all meme]({{ site.baseurl }}/images/base/I_dont_understand.gif)


Not at all.

When we humans can’t make sense of it, how come the [DNN(Dumb Neural Networks)](#ref_1) would be able to churn sense out of it. 

In Neural Networks,the **network values are computed only on the current parameters only.** This makes sense because each neuron are firing based on the current data ,and as the training period continues we adjust the weights and biases and it modifies its network based on the data passed .

![ML joke]({{ site.baseurl }}/images/rnn_1/xkcd.png)

This is a major drawback in Neural Network. How can we solve this problem ?




<a name="point_2"></a>

___


### 2. Making a way from NN to RNN
___

Well the idea that we thought was  to make a modification in the current knowledge of a Neural Network and bring out a better solution ,So the two limitations for the current neural network is:

- Variable size input 
- Memory-lization of a neural network 

**Variable Size Input**: It will be very difficult to structure a neural network  whose input size constantly varies .  If we assume the case of input size being a variable then the output size will be a variable . Thus to model the dynamic nature of input and output , a different network architecture is required.

A simpler solution would be keep input size and output size constant  of the Neural Network and to feed inputs externally . Externally meaning that we are feeding the inputs to the hidden layer portion by portion over a period of time impacting the hidden state of network at each time step *t*.


So, only option to consider variable length input and/or output is recurrent neural network, where length of the input and output is fixed like feed forward network. But effect of sequence is considered through recurrency and use of stop sequence signal. Large internal memory in the form of weights can represent internal state of the sequence.


<span class='quora-content-embed' data-name='Why-are-recurrent-NNs-often-good-with-processing-variable-length-inputs/answer/Paul-King-2'>Read <a class='quora-content-link' data-width='400' data-height='260' href='https://www.quora.com/Why-are-recurrent-NNs-often-good-with-processing-variable-length-inputs/answer/Paul-King-2' data-type='answer' data-id='23148543' data-key='052c14a85ab2363cee70d1b166ede857' load-full-answer='False' data-embed='ktbqvcy'><a href='https://www.quora.com/Paul-King-2'>Paul King</a>&#039;s <a href='/Why-are-recurrent-NNs-often-good-with-processing-variable-length-inputs#ans23148543'>answer</a> to <a href='/Why-are-recurrent-NNs-often-good-with-processing-variable-length-inputs' ref='canonical'><span class="rendered_qtext">Why are recurrent NNs often good with processing variable-length inputs?</span></a></a> on <a href='https://www.quora.com'>Quora</a><script type="text/javascript" src="https://www.quora.com/widgets/content"></script></span>

**Memory-lization**: As mentioned earlier, Neural Network only works based on current parameters alone.Therefore we will add a loop mechanism. In this loop mechanism we calculate the current output based on the previous values. Intuitively what we are doing is basically feeding back the output of the previous values to the current computation. Thus, every hidden layer neuron has the ability to process previous values of its own activity together with new input signals.

![NN RNN 1]({{ site.baseurl }}/images/rnn_1/RNN_11.png)


For example ,sentences starting with ‘are’, ‘what’, ‘which’ are all mapped as question in our mind. The idea behind that intuition is that, we have learned this information over the years and retained the information as “Memory”.

![NN RNN 2]({{ site.baseurl }}/images/rnn_1/NN_to_RNN.png)

Now since we feed the input over a period of time, our current time step computation depends on it too. Thus the output of the current time step depends on feeded input and the previous output .


The idea which we made till now is a pathway from Neural Network to Recurrent Neural Network(RNN).



<a name="point_3"></a>

___
**3. Birth of RNN**

___

Recurrent neural networks were developed in the 1980s, they had less impact due to computational power of the computers (yep, thank the graphic cards, but blame the cryptocurrency miners for making it expensive). It was first developed by John Hopfield in his Hopfield Network. The Hopfield Network uses an associative memory. An associative memory is a device which accepts an input pattern and generates an output as the stored pattern which is most closely associated with the input.

In RNN, we compute the current value based on the previous state output and current input (from now on we consider external input as input only). This gives the network a proper relation of current input to the previous output .


In Neural Network 

> ![](http://latex.codecogs.com/gif.latex?\mathbf{Z=\sigma(Wx%20+%20b)})
- W is the weight for the input
- b is the bias
- x being the input passed. 



This will be the output value of a neuron .

In RNN, we will compute current output based on current input and previous output 

> ![eq 3](http://latex.codecogs.com/gif.latex?\mathbf{h_{t}=\sigma(Wx_{t}%20+%20Uh_{t-1}%20+%20b)})
- W is the weight of the input at time t
- U is the weight of output at time t-1
- b is the bias



The idea of **Memory** in RNN is introduced through previous weights ***U***. **U** provides the significances of the previous output to the current input computation. So it can be imagined as storing some information based on previous value. And the loop mechanism which we earlier assumed can be unfolded into series of one input timestep and predicts one output. This is known as loop unrolling .

![rnn traditional]({{ site.baseurl }}/images/rnn_1/RNN_1.png)


So for our toy example, with the help of RNN we can be able to differentiate between two sentences. The image below shows how RNN solves that problem.

![rnn example 1]({{ site.baseurl }}/images/rnn_1/RNN_2.png) 


As we are at the fourth and final section of the blog, let's march onto the "how to train RNN's?"


<a name="point_4"></a>

___
### 4. BPTT for RNN
___

Now let us see how do we train such a model. Training is re-adjusting the weights and biases to be on par with the required output. 

The training procedure in the Neural Networks is to calculate final error and then calculate the gradient weights of each neuron, which gives how much influence does the neuron’s weight affect the output. Later we change (increase or decrease) the weight value with a proper learning rate.


```python

class RNN():
	def __init__(self):
        self.h = np.array([0,0,0])
        self.W_hh = np.random.standard_normal((3,3))
        self.W_xh = np.random.standard_normal((3,3))
        self.W_hy = np.random.standard_normal((3,2))
    
    def step(self,x):
        self.h = np.tanh(np.dot(self.h, self.W_hh) + np.dot(x, self.W_xh))
    

    def loss(self, y):
        y_pred = np.dot(self.h, self.W_hy)
        y_pred = np.exp(y_pred)/np.sum(np.exp(y_pred))
        
        L = -(y[0]*np.log(y_pred[0]) + y[1]*np.log(y_pred[1]))
    
    def lossFun(self, inputs, target):
        
        learning_rate = 1e-02
        """
        inputs,targets are both list of integers.
        hprev is Hx1 array of initial hidden state
        returns the loss, gradients on model parameters, and last hidden state
        """
        xs, hs = {}, {}
        hs[-1] = np.copy(self.h)
        loss = 0

        # forward pass
        for t in range(len(inputs)):
            
            hs[t] = np.tanh(np.dot(self.W_xh, inputs[t]) + np.dot(self.W_hh, hs[t-1])) # hidden state
            
        ys = np.dot(hs[t],self.W_hy,)
        ps = np.exp(ys)/(np.sum(np.exp(ys)))
        
        loss += -target[0]*np.log(ps[0]) - target[1]*np.log(ps[1]) # softmax (cross-entropy loss)

        # backward pass: compute gradients going backwards
        dWxh, dWhh, dWhy = np.zeros_like(self.W_xh), np.zeros_like(self.W_hh), np.zeros_like(self.W_hy)
        
        for t in reversed(range(len(inputs))):
            dy = np.copy(ps)
            if target[0] == 1:
                dy[0] -= 1 # backprop into y. see http://cs231n.github.io/neural-networks-case-study/#grad if confused here
            else:
                dy[1] -= 1
            dWhy += np.dot(hs[t][:,np.newaxis], dy[np.newaxis,:] )
            
            dh = np.dot(self.W_hy, dy) + dhnext # backprop into h
            dhraw = (1 - hs[t] * hs[t]) * dh # backprop through tanh nonlinearity
            
            
            dWhh += np.dot(dhraw, hs[t-1].T)
            dhnext = np.dot(self.W_hh, dhraw)
		
		for dparam in [dWxh, dWhh, dWhy]:
            np.clip(dparam, -5, 5, out=dparam) # clip to mitigate exploding gradients
        
        
        mem = dWxh*dWxh
        self.W_xh += -(learning_rate * dWxh)/np.sqrt(mem + 1e-8)  # adagrad update
        mem = dWhh*dWhh
        self.W_hh += -(learning_rate * dWhh)/ np.sqrt(mem + 1e-08)
        mem = dWhy*dWhy
        self.W_hy += -(learning_rate * dWhy)/np.sqrt(mem + 1e-8)
        
        
        return(loss, ps, target)
        

```

The training of RNN is almost the same. Since  mentioned earlier we calculate gradients to see the influence of the output. But in our calculation which we did, the current output is dependant on previous output as well.

Therefore each timestep of the unrolled recurrent neural network can be seen as an additional input of the previous output timestep 



![rnn bptt]({{ site.baseurl }}/images/rnn_1/RNN-Back.png)


Errors are then calculated and accumulated for each timestep. The network is rolled back up and the weights are updated. We need to calculate the gradient with respect to each time step separately and then add them up.




____

**Summary :**

So we covered why neural networks are not appreciated in sequential data and gave a toy example for it. We then introduced RNN and saw how its architecture would help in sequential data . 

**Future Work:**

The next blog will be more on visualizing the memories of the hidden states and more of understanding the influence of the output of the RNN for certain inputs

*Notes:*

<a name="ref_1"></a>

1.With proper construction of rules of the English language a normal Neural Network might be able to differentiate , but giving such a constraints is a tedious task. 

